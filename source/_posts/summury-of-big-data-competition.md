---
title: 2019大数据算法赛总结
date: 2019-12-09 10:32:45
categories: 机器学习
tags: [bigdata,总结,机器学习]
cover: /asset/Big-Data.jpg
---
之前一直对机器学习比较感兴趣，大三开学开始学习深度学习，正巧赶上全国高校计算机挑战赛开赛，就报名了我参加的第一个大数据方向的竞赛。这个比赛入门门槛很低，随便找个模型调用一下sklearn库就能跑出结果，但想争夺一个好的名次还是不太容易。

## 概览

报名费用：¥150（每队）

参加人数： 290队

最终排名： 62

最终得分（AUC）：0.733

使用模型：XGBOOST

<!--more-->

## 数据预处理

### 数据概况

train.csv文件中包括60000条记录，每一条记录包括Data字段和如下几列，每一列的含义如下:

![train.csv](/asset/train.png)

### 缺失数据

我们用Python读取数据首先查看有无缺失数据的情况，发现每一列都有60000条数据没有缺失值，有可能数据已经进行了缺失值的填充，后面再进行判断。

![missing_value](/asset/missing_value.png)

### 粗略观察数据和label的关系

我们对每一列和label的关系进行绘图，观察他们的相关程度和是否有线性或者非线性的关系，例如下图：

<img src="/asset/A2.png" width="60%"><img src="/asset/E2.png" width="60%">
<img src="/asset/E3.png" width="60%"><img src="/asset/E4.png" width="60%">

扔掉基本没有差别的列：['E3','E5', 'E8', 'E9','E19','E26''E29']

C2也要被丢掉，因为C2中绝大部分值都是一个相同的值，占比82.5%而其他的值的占比最多的才0.1%。

## CTR（Click-Through-Rate）问题长尾效应

CTR问题有的特点就是海量离散特征，且存在长尾效应（Long Tail Effect）：

即80%的效益来自于20%的特征，也就是说一个特征可能有成千上万种取值，但只有取值的频率最高的那些是最有用的，如果我们不对此进行处理，长尾的现象可能会降低我们模型的表现。我们由此对类别特征做了label-encoder，按照出现频率对频率较高的特征进行映射，并将出现频率很低的那些都映射为一个相同的值。

![Long_tail](/asset/Long_tail.png)

## 分箱处理

有时候我们对有连续意思的离散特征做分箱处理会使模型的表现提高。

### 举个例子

早上7点26分和早上7点27分对于是否会点击一个广告基本没有任何区别，但早上和晚上可能会有所不同。但如果直接把没有分箱的数据送给模型的话，模型会认为早上7点26分和早上7点27分就是两个完全不同的时间，因此我们可以简单的把时间信息按照早上、中午、下午、晚上划分，或者更细致一点的考虑的话，晚上人们的时间规划可能很不一样因此也可以划分的更细致一点，比如晚上按小时划分。

### 分箱方法

虽然目前有很多做分箱的理论，但因为我们需要做分箱的特征只有一列，且我们需要分箱的数据在密度图下可以明显看出区别，故我们人工估计待分箱的箱数以及分箱的位置，我们认为该种方式比聚类方法分箱有直接、暴力、可解释性强等优点。

经过尝试，我们发现对C3进行分箱是一个很好的选择，它能显著提高我们模型的表现：

![C3](/asset/C3box.png)

## 不平衡数据/Ensemble

通过观察给出的数据我们发现这是一个不平衡数据集。有83%的人不会点击广告，而只有17%的人会点击广告。就算我们训练一个只会输出不会点击广告的模型，那我们也会有83%的正确率，我们试过欠采样和SMOTE但效果都不佳，因此我们采用Ensemble方式，抽取全部点击广告的人且对不会点击广告的数据进行欠采样使得抽出的数据集平衡，有放回的抽取N次，训练N个模型取平均得到最后的结果，模型的表现会有很大的提升。

## 模型选择

我们尝试了LR，RandomForest，RandomForest+LR，GBDT，GBDT+LR，XGBOOST，XGBOOST+LR,MLR，DeepFM等模型

### 第一版模型

无脑One-hot，发现随着特征列数的增加，所有的模型都趋于一个相同的值，AUC：0.710

### 第二版模型

进行长尾数据的处理，缩减特征的维度再做One-hot，模型效果有所改善，但改善不大忘记最后结果了

### 第三版模型

细致处理长尾数据，不要One-hot，XGBOOST细致调参，得分AUC上了0.720

### 第四版模型

用DeepFM做相同的事情，重新调参，AUC：0.720

### 第五版模型

细致处理长尾数据，不要One-hot，做Ensemble，XGBOOST的AUC上了0.728，DeepFM的AUC上了0.721

### 第六版模型

将XGBOOST和DeepFM做模型融合（结果取平均），成功将AUC提到0.731

### 最终模型

细致选取使用的特征，细致处理长尾数据，不要One-hot，做Ensemble，对C3进行分箱，训练50个单独的XGBOOST做平均，AUC：0.733
